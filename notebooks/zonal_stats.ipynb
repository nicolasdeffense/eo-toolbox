{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3610jvsc74a57bd0d44a822591a3717b24d3edf137db462f6168d56f0b857c252a9153258824edbd",
   "display_name": "Python 3.6.10 64-bit ('python_3_6': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Zonal Statistics\n",
    "\n",
    "`rasterstats` is a Python module for summarizing geospatial raster datasets based on vector geometries.\n",
    "\n",
    "Geospatial data typically comes in one of two data models:\n",
    "- *rasters* which are similar to images with a regular grid of pixels whose values represent some spatial phenomenon (e.g. elevation)\n",
    "- *vectors* which are entities with discrete geometries (e.g. state boundaries).\n",
    "\n",
    "This software, `rasterstats`, exists solely to extract information from geospatial raster data based on vector geometries.\n",
    "\n",
    "This involves zonal statistics: a method of summarizing and aggregating the raster values intersecting a vector geometry. For example, zonal statistics provides answers such as the mean precipitation or maximum elevation of an administrative unit.\n",
    "\n",
    "### Statistics\n",
    "\n",
    "By default, the `zonal_stats` function will return the following statistics\n",
    "\n",
    "- min\n",
    "- max\n",
    "- mean\n",
    "- count\n",
    "\n",
    "Optionally, these statistics are also available.\n",
    "\n",
    "- sum\n",
    "- std\n",
    "- median\n",
    "- majority\n",
    "- minority\n",
    "- unique\n",
    "- range\n",
    "- nodata\n",
    "- percentile (see note below for details)\n",
    "\n",
    "https://pythonhosted.org/rasterstats/manual.html\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rasterstats : 0.14.0\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterstats\n",
    "from rasterstats import zonal_stats\n",
    "from pathlib import Path\n",
    "\n",
    "print(f'Rasterstats : {rasterstats.__version__}')"
   ]
  },
  {
   "source": [
    "## Choose the spectral index and the zonal statistic you want to calculate\n",
    "\n",
    "- min\n",
    "- max\n",
    "- mean\n",
    "- count"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'NDVI'\n",
    "\n",
    "stat = 'mean'\n",
    "\n",
    "nodata_val = -10000"
   ]
  },
  {
   "source": [
    "## Set paths for input and output directories\n",
    "\n",
    "Create directories if there are missing using `Path` and `mkdir`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Zonal Stats path are set to : /Volumes/nbdid-sst-lbrat2104/GROUP_X/WORK/ZONAL_STATS/\n"
     ]
    }
   ],
   "source": [
    "#computer_path = 'X:/'\n",
    "computer_path = '/Volumes/nbdid-sst-lbrat2104/'\n",
    "grp_letter    = 'X'\n",
    "\n",
    "# Directory for all work files\n",
    "work_path = f'{computer_path}GROUP_{grp_letter}/WORK/'\n",
    "\n",
    "\n",
    "# ----- #\n",
    "# INPUT #\n",
    "# ----- #\n",
    "\n",
    "# Directory where images are located\n",
    "index_path = f'{work_path}{index}/'\n",
    "\n",
    "# File where polygons are located\n",
    "in_situ_file = f'{work_path}IN_SITU/WALLONIA_2018_IN_SITU_ROI.shp'\n",
    "\n",
    "# ------ #\n",
    "# OUTPUT #\n",
    "# ------ #\n",
    "\n",
    "zonal_path = f'{work_path}ZONAL_STATS/'\n",
    "\n",
    "Path(zonal_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Zonal Stats path are set to : {zonal_path}')"
   ]
  },
  {
   "source": [
    "## Compute zonal statistics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New file with NDVI statistics for each polygons\n",
    "in_situ_ndvi_file = f'{zonal_path}{os.path.basename(in_situ_file)[:-4]}_with_{stat}_{index}.shp'\n",
    "\n",
    "if not os.path.isfile(in_situ_ndvi_file):\n",
    "\n",
    "    # Get list of all spetral index files and sort it\n",
    "    index_list = sorted(glob.glob(f'{index_path}*_{index}*.tif'))\n",
    "\n",
    "    # Initiate an empty list to store all \"zonal stat DataFrames\" that will be created during the loop\n",
    "    zs_dfs = []\n",
    "\n",
    "    for index_file in index_list:\n",
    "        \n",
    "        # Get date of the NDVI file\n",
    "        date = os.path.basename(index_file)[9:9+6]\n",
    "        print(date)\n",
    "\n",
    "        # Compute the zonal stat and store output in a DataFrame\n",
    "        zs_df = pd.DataFrame(zonal_stats(vectors=in_situ_file,\n",
    "                                         raster=index_file,\n",
    "                                         stats=stat))\n",
    "\n",
    "        # Replace NaN by -10000\n",
    "        zs_df[np.isnan(zs_df)] = nodata_val\n",
    "\n",
    "        # Convert to integer (if needed)\n",
    "        #zs_df = zs_df.astype(int)\n",
    "\n",
    "        # Rename column with the date\n",
    "        zs_df = zs_df.rename(columns={stat: date})\n",
    "\n",
    "        # Add the zonal stat dataframe in the list to save it\n",
    "        zs_dfs.append(zs_df)\n",
    "\n",
    "    \n",
    "    # Once the loop is done, concatenate all the dataframe in one big dataframe\n",
    "    zs_final = pd.concat(zs_dfs, axis=1)\n",
    "    print(zs_final)\n",
    "\n",
    "    \n",
    "    # Read in-situ shapefile as a GeoDataFrame\n",
    "    in_situ_gdf = gpd.read_file(in_situ_file)\n",
    "\n",
    "    # Join NDVI mean with polygons informations\n",
    "    in_situ_with_ndvi_gdf = pd.concat([in_situ_gdf, zs_final], axis=1, join=\"inner\")\n",
    "\n",
    "    # Write into a new shapefile\n",
    "    in_situ_with_ndvi_gdf.to_file(in_situ_ndvi_file)\n"
   ]
  }
 ]
}