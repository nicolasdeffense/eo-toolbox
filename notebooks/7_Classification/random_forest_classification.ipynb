{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3610jvsc74a57bd0d44a822591a3717b24d3edf137db462f6168d56f0b857c252a9153258824edbd",
   "display_name": "Python 3.6.10 64-bit ('python_3_6': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Classification using Random Forest\n",
    "\n",
    "In this chapter we will be using the Random Forest implementation provided by the `scikit-learn` library. Scikit-learn is an amazing machine learning library that provides easy and consistent interfaces to many of the most popular machine learning algorithms. It is built on top of the pre-existing scientific Python libraries, including NumPy, SciPy, and matplotlib, which makes it very easy to incorporate into your workflow. The number of available methods for accomplishing any task contained within the library is (in my opinion) its real strength. No single algorithm is best for all tasks under all circumstances, and scikit-learn helps you understand this by abstracting the details of each algorithm to simple consistent interfaces.\n",
    "\n",
    "This following figure shows the classification predictions and the decision surfaces produced for three classification problems using 9 different classifiers.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/0.15/_images/plot_classifier_comparison_0011.png\">\n",
    "\n",
    "credit : https://ceholden.github.io/open-geo-tutorial/python/chapter_5_classification.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numpy : 1.19.2\nPandas : 1.1.5\nGeoPandas : 0.8.1\nScipy: 1.5.2\nScikit-learn: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import glob, os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, plot_confusion_matrix\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "print(f'Numpy : {np.__version__}')\n",
    "print(f'Pandas : {pd.__version__}')\n",
    "print(f'GeoPandas : {gpd.__version__}')\n",
    "print(f'Scipy: {scipy.__version__}')\n",
    "print(f'Scikit-learn: {sklearn.__version__}')"
   ]
  },
  {
   "source": [
    "## Set paths for input and output directories"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification path are set to : /Volumes/nbdid-sst-lbrat2104/GROUP_X/WORK/CLASSIF/\n"
     ]
    }
   ],
   "source": [
    "#computer_path = 'X:/'\n",
    "computer_path = '/Volumes/nbdid-sst-lbrat2104/'\n",
    "grp_letter    = 'X'\n",
    "\n",
    "# Directory for all work files\n",
    "work_path = f'{computer_path}GROUP_{grp_letter}/WORK/'\n",
    "\n",
    "# ----- #\n",
    "# INPUT #\n",
    "# ----- #\n",
    "\n",
    "im_path   = f'{work_path}3_L2A_MASKED/'\n",
    "ndvi_path = f'{work_path}NDVI/'\n",
    "\n",
    "in_situ_SD_path = f'{work_path}IN_SITU_SD/'\n",
    "\n",
    "# ------ #\n",
    "# OUTPUT #\n",
    "# ------ #\n",
    "\n",
    "classif_path = f'{work_path}CLASSIF/'\n",
    "\n",
    "Path(classif_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Classification path are set to : {classif_path}')\n"
   ]
  },
  {
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "### Rasterize in-situ data shapefile\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Raster template file : /Volumes/nbdid-sst-lbrat2104/GROUP_X/WORK/3_L2A_MASKED/T31UFS_20200116T105309_B02_10m_ROI_SCL.tif\n",
      "Rasterize /Volumes/nbdid-sst-lbrat2104/GROUP_X/WORK/IN_SITU_SD/WALLONIA_2018_IN_SITU_ROI_cal.shp\n",
      "Rasterize /Volumes/nbdid-sst-lbrat2104/GROUP_X/WORK/IN_SITU_SD/WALLONIA_2018_IN_SITU_ROI_val.shp\n"
     ]
    }
   ],
   "source": [
    "# Set the field name of the class code\n",
    "\n",
    "field_name_code = 'CODE'\n",
    "\n",
    "# Set up filenames\n",
    "\n",
    "in_situ_name = 'WALLONIA_2018_IN_SITU_ROI'\n",
    "\n",
    "in_situ_cal_shp = f'{in_situ_SD_path}{in_situ_name}_cal.shp'\n",
    "in_situ_cal_tif = f'{in_situ_SD_path}{in_situ_name}_cal.tif'\n",
    "in_situ_val_shp = f'{in_situ_SD_path}{in_situ_name}_val.shp'\n",
    "in_situ_val_tif = f'{in_situ_SD_path}{in_situ_name}_val.tif'\n",
    "\n",
    "#img_temp_tif = glob.glob(f'{work_path}2_L2A_CLIPPED/*.tif')[0]\n",
    "img_temp_tif = glob.glob(f'{im_path}*.tif')[0]\n",
    "\n",
    "print(f'Raster template file : {img_temp_tif}')\n",
    "\n",
    "\n",
    "for shp, raster in zip([in_situ_cal_shp, in_situ_val_shp],[in_situ_cal_tif, in_situ_val_tif]):\n",
    "    \n",
    "    print(f'Rasterize {shp}')\n",
    "\n",
    "    # Open the shapefile with GeoPandas\n",
    "\n",
    "    in_situ_gdf = gpd.read_file(shp)\n",
    "\n",
    "    # Open the raster file you want to use as a template for rasterize\n",
    "\n",
    "    src = rasterio.open(img_temp_tif, \"r\")\n",
    "\n",
    "    # Update metadata\n",
    "    profile = src.profile\n",
    "    profile.update(nodata=0)\n",
    "\n",
    "    # Burn the features into the raster and write it out\n",
    "\n",
    "    dst = rasterio.open(raster, 'w+', **profile)\n",
    "    dst_arr = dst.read(1)\n",
    "\n",
    "    # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "\n",
    "    geom_col = in_situ_gdf.geometry\n",
    "    code_col = in_situ_gdf[field_name_code].astype(int)\n",
    "\n",
    "    shapes = ((geom,value) for geom, value in zip(geom_col, code_col))\n",
    "\n",
    "    in_situ_arr = features.rasterize(shapes=shapes,\n",
    "                                        fill=0,\n",
    "                                        out=dst_arr,\n",
    "                                        transform=dst.transform)\n",
    "\n",
    "    dst.write_band(1, in_situ_arr)\n",
    "\n",
    "    # Close rasterio objects\n",
    "    src.close()\n",
    "    dst.close()\n"
   ]
  },
  {
   "source": [
    "## List all the classification features\n",
    "\n",
    "In this case, one NDVI per month"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(570, 986, 12)\nThere are 12 features\nThe features type is : float32\n"
     ]
    }
   ],
   "source": [
    "# Get list of all files containing the features\n",
    "list_im = sorted(glob.glob(f'{ndvi_path}*.tif'))\n",
    "\n",
    "# Create an empty list to append all feature rasters one by one\n",
    "list_src_arr = []\n",
    "\n",
    "for im_file in list_im:\n",
    "\n",
    "    src = rasterio.open(im_file, \"r\")\n",
    "    im = src.read(1)\n",
    "    list_src_arr.append(im)\n",
    "    src.close()\n",
    "\n",
    "# Merge all the 2D matrices from the list into one 3D matrix\n",
    "\n",
    "feat_arr = np.dstack(list_src_arr).astype(np.float32)\n",
    "\n",
    "print(feat_arr.shape)\n",
    "print(f'There are {feat_arr.shape[2]} features')\n",
    "print(f'The features type is : {feat_arr.dtype}')\n",
    "\n",
    "#feat_arr_1 = np.stack(list_src_arr, axis=0)\n",
    "#print(feat_arr_1.shape)"
   ]
  },
  {
   "source": [
    "### Pairing Y with X\n",
    "\n",
    "Now that we have the image we want to classify (our X feature inputs), and the ROI with the land cover labels (our Y labeled data), we need to pair them up in NumPy arrays so we may feed them to Random Forest."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We have 39200 samples\n\nThe training data include 25 classes: [   6    9   12   19   20   21   36   45   62   73   91  201  311  321\n  342  541  542  821  901  931 4111 9410 9741 9742 9812] \n\nOur X matrix is sized: (39200, 12)\nOur y array is sized: (39200,)\n"
     ]
    }
   ],
   "source": [
    "# Open in-situ used for calibration\n",
    "\n",
    "src = rasterio.open(in_situ_cal_tif, \"r\")\n",
    "cal_arr = src.read(1)\n",
    "src.close()\n",
    "\n",
    "# Find how many non-zero entries we have -- i.e. how many training data samples?\n",
    "n_samples = (cal_arr > 0).sum()\n",
    "\n",
    "print(f'We have {n_samples} samples\\n')\n",
    "\n",
    "\n",
    "# What are our classification labels?\n",
    "labels = np.unique(cal_arr[cal_arr > 0])\n",
    "print(f'The training data include {labels.size} classes: {labels} \\n')\n",
    "\n",
    "\n",
    "# We will need a \"X\" matrix containing our features, and a \"y\" array containing our labels\n",
    "#     These will have n_samples rows\n",
    "#     In other languages we would need to allocate these and them loop to fill them, but NumPy can be faster\n",
    "\n",
    "X = feat_arr[cal_arr > 0, :]\n",
    "y = cal_arr[cal_arr > 0]\n",
    "\n",
    "# Replace NaN by another value\n",
    "X = np.nan_to_num(X, nan=-10)\n",
    "\n",
    "print(f'Our X matrix is sized: {X.shape}')\n",
    "print(f'Our y array is sized: {y.shape}')\n"
   ]
  },
  {
   "source": [
    "## Training the Random Forest\n",
    "\n",
    "Now that we have our X matrix of feature inputs and our y array, we can train our model.\n",
    "\n",
    "Visit this <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" target=\"_blank\">web page</a>  to find the usage of RandomForestClassifier from scikit-learn."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest training : 00:02:43.31\n"
     ]
    }
   ],
   "source": [
    "start_training = time.time()\n",
    "\n",
    "# Initialize our model with 500 trees\n",
    "rf = RandomForestClassifier(n_estimators=500, oob_score=True)\n",
    "\n",
    "# Fit our model to training data\n",
    "rf = rf.fit(X, y)\n",
    "\n",
    "end_training = time.time()\n",
    "\n",
    "# Get time elapsed during the Random Forest training\n",
    "hours, rem = divmod(end_training-start_training, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"Random Forest training : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n"
   ]
  },
  {
   "source": [
    "With our Random Forest model fit, we can check out the \"Out-of-Bag\" (OOB) prediction score:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Our OOB prediction of accuracy is: 99.1%\n"
     ]
    }
   ],
   "source": [
    "print(f'Our OOB prediction of accuracy is: {round(rf.oob_score_ * 100,2)}%')\n"
   ]
  },
  {
   "source": [
    "To help us get an idea of which features bands were important, we can look at the feature importance scores:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Band 1 importance: 0.0766\nBand 2 importance: 0.033\nBand 3 importance: 0.0832\nBand 4 importance: 0.0927\nBand 5 importance: 0.0833\nBand 6 importance: 0.0741\nBand 7 importance: 0.0899\nBand 8 importance: 0.0957\nBand 9 importance: 0.1061\nBand 10 importance: 0.0922\nBand 11 importance: 0.0918\nBand 12 importance: 0.0813\n"
     ]
    }
   ],
   "source": [
    "for band_nb, imp in enumerate(rf.feature_importances_, start=1):\n",
    "    print(f'Band {band_nb} importance: {round(imp,4)}')"
   ]
  },
  {
   "source": [
    "Let's look at a crosstabulation to see the class confusion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "predict     6   9  12    19  20   21    36   45    62   73  ...  542   821  \\\ntruth                                                       ...              \n6        2263   0   0     0   0    0     0    0     0    0  ...    0     0   \n9           0  37   0     0   0    0     0    0     0    0  ...    0     0   \n12          0   0  50     0   0    0     0    0     0    0  ...    0     0   \n19          0   0   0  1176   0    4     0    0     0    0  ...    0     0   \n20          0   0   0     0  93    0     0    0     0    0  ...    0     0   \n21          0   0   0     0   0  152     0    0     0    0  ...    0     0   \n36          0   0   0     0   0    0  2489    0     0    0  ...    0     0   \n45          0   0   0     0   0    0     0  896     0    0  ...    0     0   \n62          0   0   0     0   0    0     0    0  3219    0  ...    0     0   \n73          0   0   0     0   0    0     0    0     0  927  ...    0     0   \n91          0   0   0     0   0    0     0    0     0    0  ...    0     0   \n201         0   0   0     0   0    0     0    0     0    0  ...    0     0   \n311         0   0   0     0   0    0     0    0     0    0  ...    0     0   \n321         0   0   0     0   0    0     0    0     0    0  ...    0     0   \n342         0   0   0     0   0    0     0    0     0    0  ...    0     0   \n541         0   0   0     0   0    0     0    0     0    0  ...    0     0   \n542         0   0   0     0   0    0     0    0     0    0  ...  400     0   \n821         0   0   0     0   0    0     0    0     0    0  ...    0  1054   \n901         0   0   0     0   0    0     0    0     0    0  ...    0     0   \n931         0   0   0     0   0    0     0    0     0    0  ...    0     0   \n4111        0   0   0     0   0    0     0    0     0    0  ...    0     0   \n9410        0   0   0     0   0    0     0    0     0    0  ...    0     0   \n9741        0   0   0     0   0    0     0    0     0    0  ...    0     0   \n9742        0   0   0     0   0    0     0    0     0    0  ...    0     0   \n9812        0   0   0     0   0    0     0    0     0    0  ...    0     0   \nAll      2263  37  50  1176  93  156  2489  896  3219  927  ...  400  1054   \n\npredict   901   931  4111  9410  9741  9742  9812    All  \ntruth                                                     \n6           0     0     0     0     0     0     0   2263  \n9           0     0     0     0     0     0     0     37  \n12          0     0     0     0     0     0     0     50  \n19          0     0     0     0     0     0     0   1180  \n20          0     0     0     0     0     0     0     93  \n21          0     0     0     0     0     0     0    152  \n36          0     0     0     0     0     0     0   2489  \n45          0     0     0     0     0     0     0    896  \n62          0     0     0     0     0     0     0   3219  \n73          0     0     0     0     0     0     0    927  \n91          0     0     0     0     0     0     0   2104  \n201         0     0     0     0     0     0     0   4644  \n311         0     0     0     0     0     0     0   6212  \n321         0     0     0     0     0     0     0   4039  \n342         0     0     0     0     0     0     0    211  \n541         0     0     0     0     0     0     0    124  \n542         0     0     0     0     0     0     0    400  \n821         0     0     0     0     0     0     0   1054  \n901      4816     0     0     0     0     0     0   4816  \n931         0  1518     0     0     0     0     0   1518  \n4111        0     0  1757     0     0     0     0   1757  \n9410        0     0     0   421     0     0     0    421  \n9741        0     0     0     0    81     0     0     81  \n9742        0     0     0     0     0   196     0    196  \n9812        0     0     0     0     0     0   317    317  \nAll      4816  1518  1757   421    81   196   317  39200  \n\n[26 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>predict</th>\n      <th>6</th>\n      <th>9</th>\n      <th>12</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>36</th>\n      <th>45</th>\n      <th>62</th>\n      <th>73</th>\n      <th>...</th>\n      <th>542</th>\n      <th>821</th>\n      <th>901</th>\n      <th>931</th>\n      <th>4111</th>\n      <th>9410</th>\n      <th>9741</th>\n      <th>9742</th>\n      <th>9812</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>truth</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>2263</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2263</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1176</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1180</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>152</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2489</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2489</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>896</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>896</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3219</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3219</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>927</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>927</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2104</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4644</td>\n    </tr>\n    <tr>\n      <th>311</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6212</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4039</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211</td>\n    </tr>\n    <tr>\n      <th>541</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>124</td>\n    </tr>\n    <tr>\n      <th>542</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>400</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1054</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1054</td>\n    </tr>\n    <tr>\n      <th>901</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4816</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4816</td>\n    </tr>\n    <tr>\n      <th>931</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1518</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1518</td>\n    </tr>\n    <tr>\n      <th>4111</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1757</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1757</td>\n    </tr>\n    <tr>\n      <th>9410</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>421</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>421</td>\n    </tr>\n    <tr>\n      <th>9741</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0</td>\n      <td>0</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>9742</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>196</td>\n      <td>0</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>9812</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>317</td>\n      <td>317</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>2263</td>\n      <td>37</td>\n      <td>50</td>\n      <td>1176</td>\n      <td>93</td>\n      <td>156</td>\n      <td>2489</td>\n      <td>896</td>\n      <td>3219</td>\n      <td>927</td>\n      <td>...</td>\n      <td>400</td>\n      <td>1054</td>\n      <td>4816</td>\n      <td>1518</td>\n      <td>1757</td>\n      <td>421</td>\n      <td>81</td>\n      <td>196</td>\n      <td>317</td>\n      <td>39200</td>\n    </tr>\n  </tbody>\n</table>\n<p>26 rows × 26 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Setup a dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['truth'] = y\n",
    "df['predict'] = rf.predict(X)\n",
    "\n",
    "# Cross-tabulate predictions\n",
    "\n",
    "cross_tab = pd.crosstab(df['truth'], df['predict'], margins=True)\n",
    "display(cross_tab)\n"
   ]
  },
  {
   "source": [
    "## Predicting the rest of the image\n",
    "\n",
    "With our Random Forest classifier fit, we can now proceed by trying to classify the entire image."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reshaped from (570, 986, 12) to (562020, 12)\n",
      "Random Forest training : 00:02:01.43\n"
     ]
    }
   ],
   "source": [
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "\n",
    "img = feat_arr\n",
    "\n",
    "img = np.nan_to_num(img, nan=-10)\n",
    "\n",
    "new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "\n",
    "img_as_array = img[:, :, :].reshape(new_shape)\n",
    "\n",
    "print(f'Reshaped from {img.shape} to {img_as_array.shape}')\n",
    "\n",
    "\n",
    "start_classification = time.time()\n",
    "\n",
    "# Now predict for each pixel\n",
    "class_prediction = rf.predict(img_as_array)\n",
    "\n",
    "# Reshape our classification map\n",
    "class_prediction = class_prediction.reshape(img[:, :, 0].shape)\n",
    "\n",
    "end_classification = time.time()\n",
    "\n",
    "hours, rem = divmod(end_classification-start_classification, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"Random Forest training : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Write Classification product into a GeoTIFF file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of image : (570, 986)\n"
     ]
    }
   ],
   "source": [
    "classif_tif = f'{classif_path}Classif_RF_with_NDVI.tif'\n",
    "\n",
    "print(f'Size of image : {class_prediction.shape}')\n",
    "\n",
    "# Open template image to get metadata\n",
    "src = rasterio.open(img_temp_tif)\n",
    "im = src.read(1)\n",
    "profile = src.profile\n",
    "\n",
    "# Write classification image\n",
    "dst = rasterio.open(classif_tif, 'w', **profile)\n",
    "dst.write(class_prediction, 1)\n",
    "\n",
    "# Close rasterio objects\n",
    "src.close()\n",
    "dst.close()"
   ]
  }
 ]
}