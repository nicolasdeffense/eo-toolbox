{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries successfully imported!\n",
      "Scikit-learn : 0.24.2\n"
     ]
    }
   ],
   "source": [
    "import glob, os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from rasterio import features\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "print('All libraries successfully imported!')\n",
    "print(f'Scikit-learn : {sklearn.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification path is set to : /export/miro/ndeffense/LBRAT2104/GROUP_X/WORK/CLASSIF/\n"
     ]
    }
   ],
   "source": [
    "computer_path = '/export/miro/ndeffense/LBRAT2104/'\n",
    "grp_letter    = 'X'\n",
    "\n",
    "data_path = f'{computer_path}data/'                     # Directory with data shared by the assistant\n",
    "work_path = f'{computer_path}GROUP_{grp_letter}/WORK/'  # Directory for all work files\n",
    "\n",
    "# Input directories\n",
    "in_situ_path = f'{work_path}IN_SITU/'\n",
    "s2_path      = f'{work_path}3_L2A_MASKED/'\n",
    "ndvi_path    = f'{work_path}NDVI/'\n",
    "s1_path      = f'{data_path}S1_GRD/'\n",
    "lut_path     = f'{data_path}LUT/'\n",
    "\n",
    "# Output directory\n",
    "classif_path = f'{work_path}CLASSIF/'\n",
    "\n",
    "Path(classif_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Classification path is set to : {classif_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'NAMUR'\n",
    "year = '2020'\n",
    "\n",
    "no_data = -999\n",
    "\n",
    "ws = 3          # Window size (filtering post classification)\n",
    "\n",
    "# Field used for classification\n",
    "field_classif_code = 'grp_1_nb'\n",
    "field_classif_name = 'grp_1'\n",
    "\n",
    "# Field used for reclassification\n",
    "field_reclassif_code = 'grp_A_nb'\n",
    "field_reclassif_name = 'grp_A'\n",
    "\n",
    "# Group of features used in classification\n",
    "feat_nb = 1\n",
    "\n",
    "if feat_nb == 1:\n",
    "    feat_name = ['NDVI']\n",
    "elif feat_nb == 2:\n",
    "    feat_name = ['NDVI','S1_monthly_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_situ_cal_shp = f'{in_situ_path}{site}_{year}_IN_SITU_ROI_CAL.shp'\n",
    "\n",
    "s4s_lut_csv = f'{lut_path}crop_dictionary_new.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_situ_cal_tif = f'{in_situ_path}{site}_{year}_IN_SITU_ROI_CAL.tif'\n",
    "\n",
    "classif_tif   = f'{classif_path}{site}_{year}_classif_RF_feat_{feat_nb}_{field_classif_name}.tif'\n",
    "reclassif_tif = f'{classif_path}{site}_{year}_classif_RF_feat_{feat_nb}_{field_classif_name}_reclassify_{field_reclassif_name}.tif'\n",
    "reclassif_filter_tif = f'{classif_path}{site}_{year}_classif_RF_feat_{feat_nb}_{field_classif_name}_reclassify_{field_reclassif_name}_filter_ws_{ws}.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare classification features associated to *in situ* data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Rasterize *in situ* data calibration shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster template file : /export/miro/ndeffense/LBRAT2104/GROUP_X/WORK/3_L2A_MASKED/T31UFS_20201118T104329_B04_10m_ROI_SCL.tif\n",
      "The CRS of in situ data is    : 32631\n",
      "The CRS of raster template is : 32631\n",
      "CRS are the same\n",
      "Rasterize starts : /export/miro/ndeffense/LBRAT2104/GROUP_X/WORK/IN_SITU/NAMUR_2020_IN_SITU_ROI_CAL.shp\n",
      "Rasterize is done : /export/miro/ndeffense/LBRAT2104/GROUP_X/WORK/IN_SITU/NAMUR_2020_IN_SITU_ROI_CAL.tif\n"
     ]
    }
   ],
   "source": [
    "# Open the calibration polygons with GeoPandas\n",
    "in_situ_gdf = gpd.read_file(in_situ_cal_shp)\n",
    "\n",
    "# Open the raster file you want to use as a template for rasterize\n",
    "img_temp_tif = glob.glob(f'{s2_path}*.tif')[0]\n",
    "\n",
    "print(f'Raster template file : {img_temp_tif}')\n",
    "\n",
    "src = rasterio.open(img_temp_tif, \"r\")\n",
    "\n",
    "# Update metadata\n",
    "\n",
    "out_meta = src.meta\n",
    "out_meta.update(nodata=no_data)\n",
    "\n",
    "crs_shp = str(in_situ_gdf.crs).split(\":\",1)[1]\n",
    "crs_tif = str(src.crs).split(\":\",1)[1]\n",
    "\n",
    "print(f'The CRS of in situ data is    : {crs_shp}')\n",
    "print(f'The CRS of raster template is : {crs_tif}')\n",
    "\n",
    "if crs_shp == crs_tif:\n",
    "    print(\"CRS are the same\")\n",
    "\n",
    "    print(f'Rasterize starts : {in_situ_cal_shp}')\n",
    "\n",
    "    # Burn the features into the raster and write it out\n",
    "\n",
    "    dst = rasterio.open(in_situ_cal_tif, 'w+', **out_meta)\n",
    "    dst_arr = dst.read(1)\n",
    "\n",
    "    # This is where we create a generator of geom, value pairs to use in rasterizing\n",
    "\n",
    "    geom_col = in_situ_gdf.geometry\n",
    "    code_col = in_situ_gdf[field_classif_code].astype(int)\n",
    "\n",
    "    shapes = ((geom,value) for geom, value in zip(geom_col, code_col))\n",
    "\n",
    "    in_situ_arr = features.rasterize(shapes=shapes,\n",
    "                                     fill=no_data,\n",
    "                                     out=dst_arr,\n",
    "                                     transform=dst.transform)\n",
    "\n",
    "    dst.write_band(1, in_situ_arr)\n",
    "\n",
    "    print(f'Rasterize is done : {in_situ_cal_tif}')\n",
    "\n",
    "    # Close rasterio objects\n",
    "    src.close()\n",
    "    dst.close()\n",
    "\n",
    "else:\n",
    "    print('CRS are different --> repoject in-situ data shapefile with \"to_crs\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 List all the classification features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty list to append all feature rasters one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_src_arr = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 NDVI image per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features : (570, 986)\n",
      "Number of features : 12\n"
     ]
    }
   ],
   "source": [
    "if 'NDVI' in feat_name:\n",
    "\n",
    "    list_im = sorted(glob.glob(f'{ndvi_path}*.tif'))\n",
    "\n",
    "    for im_file in list_im:\n",
    "\n",
    "        src = rasterio.open(im_file, \"r\")\n",
    "        im = src.read(1)\n",
    "        list_src_arr.append(im)\n",
    "        src.close()\n",
    "        \n",
    "    print(f'Shape of features : {im.shape}')\n",
    "    print(f'Number of features : {len(list_src_arr)}')\n",
    "\n",
    "else:\n",
    "    print(\"No NDVI in the set of features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S1 monthly mean composite (obtained with Google Earth Engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No S1 monthly mean in the set of features\n"
     ]
    }
   ],
   "source": [
    "if 'S1_monthly_mean' in feat_name:\n",
    "\n",
    "    s1_montlhy_mean_tif = f'{s1_path}monthly_mean_{site}_{year}.tif'\n",
    "\n",
    "    src = rasterio.open(s1_montlhy_mean_tif, \"r\")\n",
    "    im = src.read()\n",
    "    src.close()\n",
    "\n",
    "    for i in range(len(im)):\n",
    "        band = im[i]\n",
    "        list_src_arr.append(band)\n",
    "\n",
    "    print(f'Shape of features : {band.shape}')\n",
    "    print(f'Number of features : {len(list_src_arr)}')\n",
    "\n",
    "else:\n",
    "    print(\"No S1 monthly mean in the set of features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the 2D matrices from the list into one 3D matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 986, 12)\n",
      "There are 12 features\n",
      "The features type is : float32\n"
     ]
    }
   ],
   "source": [
    "feat_arr = np.dstack(list_src_arr).astype(np.float32)\n",
    "\n",
    "print(feat_arr.shape)\n",
    "print(f'There are {feat_arr.shape[2]} features')\n",
    "print(f'The features type is : {feat_arr.dtype}')\n",
    "\n",
    "#feat_arr_1 = np.stack(list_src_arr, axis=0)\n",
    "#print(feat_arr_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Pairing *in situ* data (Y) with EO classification features (X)\n",
    "\n",
    "Now that we have the image we want to classify (our X feature inputs), and the ROI with the land cover labels (our Y labeled data), we need to pair them up in NumPy arrays so we may feed them to Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 34909 samples (= calibration pixels)\n"
     ]
    }
   ],
   "source": [
    "# Open in-situ used for calibration\n",
    "\n",
    "src = rasterio.open(in_situ_cal_tif, \"r\")\n",
    "cal_arr = src.read(1)\n",
    "src.close()\n",
    "\n",
    "# Find how many labeled entries we have -- i.e. how many training data samples?\n",
    "n_samples = (cal_arr != no_data).sum()\n",
    "\n",
    "print(f'We have {n_samples} samples (= calibration pixels)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are our classification labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data include 19 classes: [   3   21   22   69   81   84  121 1111 1121 1152 1171 1192 1435 1511\n",
      " 1771 1811 1911 1923 9212]\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(cal_arr[cal_arr != no_data])\n",
    "\n",
    "print(f'The training data include {labels.size} classes: {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need :\n",
    "- **\"X\" 2D matrix** containing classification features\n",
    "- **\"y\" 1D matrix** containing our labels\n",
    "\n",
    "These will have `n_samples` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our X matrix is sized: (34909, 12)\n",
      "Our y array is sized: (34909,)\n"
     ]
    }
   ],
   "source": [
    "X = feat_arr[cal_arr != no_data, :]\n",
    "y = cal_arr[cal_arr != no_data]\n",
    "\n",
    "# Replace NaN in classification features by the no_data value\n",
    "X = np.nan_to_num(X, nan=no_data)\n",
    "\n",
    "print(f'Our X matrix is sized: {X.shape}')\n",
    "print(f'Our y array is sized: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our X 2D-matrix of feature inputs and our y 1D-matrix containing the labels, we can train our model.\n",
    "\n",
    "Visit this <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\" target=\"_blank\">web page</a>  to find the usage of RandomForestClassifier from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training : 00:00:21.34\n"
     ]
    }
   ],
   "source": [
    "start_training = time.time()\n",
    "\n",
    "# Initialize our model\n",
    "rf = RandomForestClassifier(n_estimators=100, # The number of trees in the forest.\n",
    "                            bootstrap=True,   # Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "                            oob_score=True)   # Whether to use out-of-bag samples to estimate the generalization score. Only available if bootstrap=True.\n",
    "\n",
    "# Fit our model to training data\n",
    "rf = rf.fit(X, y)\n",
    "\n",
    "end_training = time.time()\n",
    "\n",
    "# Get time elapsed during the Random Forest training\n",
    "hours, rem = divmod(end_training-start_training, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"Random Forest training : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our Random Forest model fit, we can check out the \"Out-of-Bag\" (OOB) prediction score.\n",
    "\n",
    "> Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when oob_score is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our OOB prediction of accuracy is: 99.36%\n"
     ]
    }
   ],
   "source": [
    "print(f'Our OOB prediction of accuracy is: {round(rf.oob_score_ * 100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help us get an idea of which features bands were important, we can look at the feature importance scores.\n",
    "\n",
    "> The impurity-based feature importances. The higher, the more important the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_band</th>\n",
       "      <th>gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.128379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.128083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.116532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.099405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.094935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.091488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.077598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.075730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.057790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.053143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.049446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.027471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_band      gini\n",
       "6           7  0.128379\n",
       "7           8  0.128083\n",
       "4           5  0.116532\n",
       "2           3  0.099405\n",
       "8           9  0.094935\n",
       "3           4  0.091488\n",
       "9          10  0.077598\n",
       "0           1  0.075730\n",
       "10         11  0.057790\n",
       "11         12  0.053143\n",
       "5           6  0.049446\n",
       "1           2  0.027471"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_band_list = []\n",
    "gini_list      = []\n",
    "\n",
    "for band_nb, imp in enumerate(rf.feature_importances_, start=1):\n",
    "\n",
    "    feat_band_list.append(band_nb)\n",
    "    gini_list.append(imp)\n",
    "\n",
    "gini_dict = {'feat_band':feat_band_list,'gini':gini_list}   \n",
    "\n",
    "gini_df = pd.DataFrame(gini_dict).sort_values(by='gini', ascending=False)\n",
    "\n",
    "gini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a crosstabulation to see the class confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predict</th>\n",
       "      <th>3</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>69</th>\n",
       "      <th>81</th>\n",
       "      <th>84</th>\n",
       "      <th>121</th>\n",
       "      <th>1111</th>\n",
       "      <th>1121</th>\n",
       "      <th>1152</th>\n",
       "      <th>1171</th>\n",
       "      <th>1192</th>\n",
       "      <th>1435</th>\n",
       "      <th>1511</th>\n",
       "      <th>1771</th>\n",
       "      <th>1811</th>\n",
       "      <th>1911</th>\n",
       "      <th>1923</th>\n",
       "      <th>9212</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1551</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2059</td>\n",
       "      <td>0</td>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9212</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5971</td>\n",
       "      <td>1551</td>\n",
       "      <td>124</td>\n",
       "      <td>2296</td>\n",
       "      <td>1353</td>\n",
       "      <td>183</td>\n",
       "      <td>566</td>\n",
       "      <td>7403</td>\n",
       "      <td>2132</td>\n",
       "      <td>1663</td>\n",
       "      <td>534</td>\n",
       "      <td>1477</td>\n",
       "      <td>1176</td>\n",
       "      <td>1577</td>\n",
       "      <td>2454</td>\n",
       "      <td>1850</td>\n",
       "      <td>403</td>\n",
       "      <td>2059</td>\n",
       "      <td>137</td>\n",
       "      <td>34909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predict     3    21   22    69    81   84  121  1111  1121  1152  1171  1192  \\\n",
       "truth                                                                          \n",
       "3        5971     0    0     0     0    0    0     0     0     0     0     0   \n",
       "21          0  1551    0     0     0    0    0     0     0     0     0     0   \n",
       "22          0     0  124     0     0    0    0     0     0     0     0     0   \n",
       "69          0     0    0  2296     0    0    0     0     0     0     0     0   \n",
       "81          0     0    0     0  1338    0    0     0     0     0     0     0   \n",
       "84          0     0    0     0     0  183    0     0     0     0     0     0   \n",
       "121         0     0    0     0     0    0  566     0     0     0     0     0   \n",
       "1111        0     0    0     0     0    0    0  7403     0     0     0     0   \n",
       "1121        0     0    0     0     0    0    0     0  2132     0     0     0   \n",
       "1152        0     0    0     0     0    0    0     0     0  1663     0     0   \n",
       "1171        0     0    0     0     0    0    0     0     0     0   534     0   \n",
       "1192        0     0    0     0     0    0    0     0     0     0     0  1477   \n",
       "1435        0     0    0     0     0    0    0     0     0     0     0     0   \n",
       "1511        0     0    0     0     0    0    0     0     0     0     0     0   \n",
       "1771        0     0    0     0     0    0    0     0     0     0     0     0   \n",
       "1811        0     0    0     0     0    0    0     0     0     0     0     0   \n",
       "1911        0     0    0     0     0    0    0     0     0     0     0     0   \n",
       "1923        0     0    0     0     0    0    0     0     0     0     0     0   \n",
       "9212        0     0    0     0    15    0    0     0     0     0     0     0   \n",
       "All      5971  1551  124  2296  1353  183  566  7403  2132  1663   534  1477   \n",
       "\n",
       "predict  1435  1511  1771  1811  1911  1923  9212    All  \n",
       "truth                                                     \n",
       "3           0     0     0     0     0     0     0   5971  \n",
       "21          0     0     0     0     0     0     0   1551  \n",
       "22          0     0     0     0     0     0     0    124  \n",
       "69          0     0     0     0     0     0     0   2296  \n",
       "81          0     0     0     0     0     0     0   1338  \n",
       "84          0     0     0     0     0     0     0    183  \n",
       "121         0     0     0     0     0     0     0    566  \n",
       "1111        0     0     0     0     0     0     0   7403  \n",
       "1121        0     0     0     0     0     0     0   2132  \n",
       "1152        0     0     0     0     0     0     0   1663  \n",
       "1171        0     0     0     0     0     0     0    534  \n",
       "1192        0     0     0     0     0     0     0   1477  \n",
       "1435     1176     0     0     0     0     0     0   1176  \n",
       "1511        0  1577     0     0     0     0     0   1577  \n",
       "1771        0     0  2454     0     0     0     0   2454  \n",
       "1811        0     0     0  1850     0     0     0   1850  \n",
       "1911        0     0     0     0   403     0     0    403  \n",
       "1923        0     0     0     0     0  2059     0   2059  \n",
       "9212        0     0     0     0     0     0   137    152  \n",
       "All      1176  1577  2454  1850   403  2059   137  34909  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup a dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['truth'] = y\n",
    "df['predict'] = rf.predict(X)\n",
    "\n",
    "# Cross-tabulate predictions\n",
    "\n",
    "cross_tab = pd.crosstab(df['truth'], df['predict'], margins=True)\n",
    "display(cross_tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbelievable? I highly doubt the real confusion matrix will be 100% accuracy. What is likely going on is that we used a large number of trees within a machine learning algorithm to best figure out the pattern in our training data. Given enough information and effort, this algorithm precisely learned what we gave it. Asking to validate a machine learning algorithm on the training data is a useless exercise that will overinflate the accuracy.\n",
    "\n",
    "Instead, we could have done a crossvalidation approach where we train on a subset the dataset, and then predict and assess the accuracy using the sections we didn't train it on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predict the rest of the image\n",
    "\n",
    "With our Random Forest classifier fit, we can now proceed by trying to classify the entire image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped from (570, 986, 12) to (562020, 12)\n",
      "Random Forest training : 00:00:24.16\n",
      "[[   3    3   81 ...    3    3    3]\n",
      " [   3    3    3 ...    3    3   22]\n",
      " [   3    3   69 ...    3   22 1121]\n",
      " ...\n",
      " [  69   69   69 ... 1111 1111 1111]\n",
      " [  69   69   69 ... 1111 1111 1111]\n",
      " [  69   69   69 ... 1111 1111 1111]]\n"
     ]
    }
   ],
   "source": [
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "\n",
    "img = feat_arr\n",
    "\n",
    "img = np.nan_to_num(img, nan=no_data)\n",
    "\n",
    "new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "\n",
    "img_as_array = img[:, :, :].reshape(new_shape)\n",
    "\n",
    "print(f'Reshaped from {img.shape} to {img_as_array.shape}')\n",
    "\n",
    "start_classification = time.time()\n",
    "\n",
    "# Now predict for each pixel\n",
    "class_prediction = rf.predict(img_as_array)\n",
    "\n",
    "# Reshape our classification map\n",
    "class_prediction = class_prediction.reshape(img[:, :, 0].shape)\n",
    "\n",
    "end_classification = time.time()\n",
    "\n",
    "hours, rem = divmod(end_classification-start_classification, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"Random Forest training : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "print(class_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reclassify classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Open LUT and sort values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp_1_nb</th>\n",
       "      <th>grp_1</th>\n",
       "      <th>grp_A_nb</th>\n",
       "      <th>grp_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "      <td>0</td>\n",
       "      <td>Remove</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grp_1_nb   grp_1  grp_A_nb   grp_A\n",
       "0          0  Remove         0  Remove\n",
       "71         0  Remove         0  Remove\n",
       "75         0  Remove         0  Remove\n",
       "82         0  Remove         0  Remove\n",
       "86         0  Remove         0  Remove"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lut_df = pd.read_csv(s4s_lut_csv, sep=';')\n",
    "\n",
    "lut_df = lut_df.sort_values(by=field_classif_code, ascending=True)\n",
    "\n",
    "display(lut_df[[field_classif_code, field_classif_name, field_reclassif_code, field_reclassif_name]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Reclassify prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification : \n",
      " [[   3    3   81 ...    3    3    3]\n",
      " [   3    3    3 ...    3    3   22]\n",
      " [   3    3   69 ...    3   22 1121]\n",
      " ...\n",
      " [  69   69   69 ... 1111 1111 1111]\n",
      " [  69   69   69 ... 1111 1111 1111]\n",
      " [  69   69   69 ... 1111 1111 1111]]\n",
      "Re-classification : \n",
      " [[  3   3   8 ...   3   3   3]\n",
      " [  3   3   3 ...   3   3  22]\n",
      " [  3   3   6 ...   3  22 112]\n",
      " ...\n",
      " [  6   6   6 ... 111 111 111]\n",
      " [  6   6   6 ... 111 111 111]\n",
      " [  6   6   6 ... 111 111 111]]\n"
     ]
    }
   ],
   "source": [
    "reclass_prediction = np.copy(class_prediction)\n",
    "\n",
    "for i, row in lut_df.iterrows():\n",
    "    \n",
    "    old_class = row[field_classif_code]\n",
    "    new_class = row[field_reclassif_code]\n",
    "\n",
    "    #print(f'{old_class} --> {new_class}')\n",
    "\n",
    "    #array[np.where(array == old_class)] = new_class\n",
    "\n",
    "    reclass_prediction[reclass_prediction == old_class] = new_class\n",
    "\n",
    "print(f'Classification : \\n {class_prediction}')\n",
    "print(f'Re-classification : \\n {reclass_prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter classification with moving window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-classification : \n",
      " [[  3   3   8 ...   3   3   3]\n",
      " [  3   3   3 ...   3   3  22]\n",
      " [  3   3   6 ...   3  22 112]\n",
      " ...\n",
      " [  6   6   6 ... 111 111 111]\n",
      " [  6   6   6 ... 111 111 111]\n",
      " [  6   6   6 ... 111 111 111]]\n",
      "Re-classification with filter : \n",
      " [[[  3   3   3 ...   3   3   3]\n",
      "  [  3   3   3 ...   3   3   3]\n",
      "  [  3   3   3 ...   3   3 112]\n",
      "  ...\n",
      "  [  6   6   6 ... 111 111 111]\n",
      "  [  6   6   6 ... 111 111 111]\n",
      "  [  6   6   6 ... 111 111 111]]]\n"
     ]
    }
   ],
   "source": [
    "sizey = reclass_prediction.shape[0]\n",
    "sizex = reclass_prediction.shape[1]\n",
    "\n",
    "X = np.pad(reclass_prediction, ((1,1),(1,1)), 'edge')\n",
    "\n",
    "majority = np.empty((sizey,sizex), dtype='int16')\n",
    "\n",
    "for i in range(sizey):\n",
    "    for j in range(sizex):\n",
    "        window = X[i:i+ws,j:j+ws]\n",
    "        window = window.flatten()\n",
    "        counts = np.bincount(window)\n",
    "        maj = np.argmax(counts)\n",
    "        majority[i,j]= maj\n",
    "\n",
    "majority = majority.reshape((1,sizey,sizex))\n",
    "\n",
    "print(f'Re-classification : \\n {reclass_prediction}')\n",
    "print(f'Re-classification with filter : \\n {majority}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write classification products into GeoTIFF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open template image to get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff', 'dtype': 'int16', 'nodata': -10000.0, 'width': 986, 'height': 570, 'count': 1, 'crs': CRS({'init': 'epsg:32631'}), 'transform': Affine(10.0, 0.0, 627260.0,\n",
       "       0.0, -10.0, 5596180.0), 'tiled': False, 'compress': 'lzw', 'interleave': 'band'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with rasterio.open(img_temp_tif) as src:\n",
    "    profile = src.profile\n",
    "\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Write classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(classif_tif, \"w\", **profile) as dst:\n",
    "    dst.write(class_prediction, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Write re-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(reclassif_tif, \"w\", **profile) as dst:\n",
    "    dst.write(reclass_prediction, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Write re-classification with moving window filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(reclassif_filter_tif, \"w\", **profile) as dst:\n",
    "    dst.write(majority)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('python_3_6': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
